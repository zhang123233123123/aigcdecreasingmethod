import streamlit as st
import io
import tempfile
import os
from docx import Document
from openai import OpenAI
import base64
import re
import json
from stqdm import stqdm
import requests

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é™AIGCç‡",
    page_icon="âœï¸",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'doc' not in st.session_state:
    st.session_state.doc = None
if 'paragraphs' not in st.session_state:
    st.session_state.paragraphs = []
if 'modified_paragraphs' not in st.session_state:
    st.session_state.modified_paragraphs = []
if 'ai_probabilities' not in st.session_state:
    st.session_state.ai_probabilities = []
if 'selected_text' not in st.session_state:
    st.session_state.selected_text = ""
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main {
        padding: 1rem;
    }
    .stTextArea textarea {
        min-height: 200px;
        background-color: white;
        border-radius: 10px;
        border: 1px solid #ddd;
        padding: 15px;
    }
    .text-card {
        background-color: white;
        border-radius: 10px;
        border: 1px solid #ddd;
        padding: 15px;
        margin: 10px 0;
        min-height: 200px;
    }
    .button-container {
        display: flex;
        gap: 10px;
        margin: 10px 0;
    }
    .reset-button {
        background-color: #f0f2f6;
        color: black;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
    }
    .generate-button {
        background-color: #4c6ef5;
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        cursor: pointer;
    }
    .word-count {
        color: #666;
        font-size: 0.9em;
    }
    .warning-message {
        background-color: #fff3cd;
        color: #856404;
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# é¡µé¢æ ‡é¢˜
st.title("é™AIGCç‡")

# APIå¯†é’¥è¾“å…¥
api_key = st.text_input("è¯·è¾“å…¥æ‚¨çš„DeepSeek APIå¯†é’¥", 
                        value=st.session_state.api_key,
                        type="password",
                        help="éœ€è¦DeepSeek APIå¯†é’¥æ‰èƒ½åˆ†æå’Œä¼˜åŒ–æ–‡æœ¬")

if api_key != st.session_state.api_key:
    st.session_state.api_key = api_key

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼ Wordæ–‡æ¡£", type=["docx"], 
                                help="ä»…æ”¯æŒ.docxæ ¼å¼çš„Wordæ–‡æ¡£")

if uploaded_file is not None:
    if process_docx_upload(uploaded_file):
        st.success(f"æˆåŠŸåŠ è½½æ–‡æ¡£: {uploaded_file.name}")

# å·¦å³ä¸¤æ å¸ƒå±€
col1, col2 = st.columns(2)

with col1:
    st.markdown("### åŸæ–‡")
    if st.session_state.paragraphs:
        selected_para_index = st.selectbox(
            "é€‰æ‹©è¦ç¼–è¾‘çš„æ®µè½", 
            options=list(range(len(st.session_state.paragraphs))),
            format_func=lambda x: f"æ®µè½ {x+1}"
        )
        
        # æ˜¾ç¤ºåŸæ–‡
        st.markdown('<div class="text-card">', unsafe_allow_html=True)
        st.write(st.session_state.paragraphs[selected_para_index])
        st.markdown('</div>', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå­—æ•°
        word_count = len(st.session_state.paragraphs[selected_para_index])
        st.markdown(f'<p class="word-count">{word_count}/1000 å­—ç¬¦</p>', unsafe_allow_html=True)

with col2:
    st.markdown("### ä¼˜åŒ–åçš„æ–‡æœ¬")
    if st.session_state.paragraphs:
        # æ˜¾ç¤ºä¼˜åŒ–åçš„æ–‡æœ¬
        st.markdown('<div class="text-card">', unsafe_allow_html=True)
        if selected_para_index < len(st.session_state.modified_paragraphs):
            st.write(st.session_state.modified_paragraphs[selected_para_index])
        st.markdown('</div>', unsafe_allow_html=True)

# æŒ‰é’®åŒºåŸŸ
if st.session_state.paragraphs:
    st.markdown('<div class="button-container">', unsafe_allow_html=True)
    
    # é‡ç½®æŒ‰é’®
    if st.button("é‡ç½®", key="reset"):
        st.session_state.modified_paragraphs[selected_para_index] = st.session_state.paragraphs[selected_para_index]
        st.experimental_rerun()
    
    # ä¸€é”®ç”ŸæˆæŒ‰é’®
    if st.button("ä¸€é”®ç”Ÿæˆ", key="generate"):
        if not st.session_state.api_key:
            st.error("è¯·è¾“å…¥DeepSeek APIå¯†é’¥")
        else:
            with st.spinner("æ­£åœ¨ä¼˜åŒ–æ–‡æœ¬..."):
                text = st.session_state.paragraphs[selected_para_index]
                # è·å–å½“å‰æ®µè½çš„AIæ¦‚ç‡
                ai_prob = st.session_state.ai_probabilities[selected_para_index]
                optimized_text = analyze_text_with_deepseek(text, st.session_state.api_key, ai_prob)
                st.session_state.modified_paragraphs[selected_para_index] = optimized_text
                st.experimental_rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

# æ¸©é¦¨æç¤º
st.markdown('<div class="warning-message">ä¸ºä¿æŠ¤ç”¨æˆ·å†…å®¹å®‰å…¨ï¼Œæ®µè½å¤„ç†çš„ç»“æœä¸ä¼šä¿å­˜ï¼Œè¯·åŠæ—¶å¤åˆ¶åˆ°è‡ªå·±çš„æ–‡ä»¶ä¸­ã€‚</div>', unsafe_allow_html=True)

# DeepSeek API è°ƒç”¨å‡½æ•°
def analyze_text_with_deepseek(text, api_key, ai_probability=50):
    """ä½¿ç”¨DeepSeek APIåˆ†ææ–‡æœ¬çš„AIç”Ÿæˆæ¦‚ç‡å¹¶æä¾›ä¼˜åŒ–å»ºè®®ï¼Œä¼ å…¥ç”¨æˆ·é€‰æ‹©çš„AIç‡"""
    try:
        # ç›´æ¥ä½¿ç”¨requestsåº“è°ƒç”¨APIè€Œä¸æ˜¯OpenAIå®¢æˆ·ç«¯
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„AIç‡æ„å»ºä¸åŒçš„æç¤ºè¯
        system_prompt = f"""
        You are a professional text optimization assistant. Please analyze the following text and optimize it based on {ai_probability}% AI detection probability:

        Please optimize the text using these core strategies:
        1. Strategic Content Adjustment:
          - Identify paragraphs with obvious AI-generated characteristics and consider removing non-essential content
          - Rewrite or reduce high-risk sentences while maintaining core meaning
        
        2. Citation Strategy:
          - Add appropriate academic references and cross-references to improve text credibility
          - Use proper citation formats to reduce the probability of being identified as AI-generated
          - Rewrite high-risk content as quoted opinions from others
        
        3. Paragraph Restructuring:
          - Break higher-risk long paragraphs into multiple shorter paragraphs to avoid wholesale flagging
          - Logically divide large paragraphs into 2-3 smaller ones based on content flow
          - Add transition sentences between paragraphs to maintain logical coherence
        
        4. Word Choice and Sentence Variation:
          - Replace obvious AI-style vocabulary with more conversational expressions
          - Introduce natural language markers and conversational phrases (e.g., "actually," "to be honest," "it's worth noting")
          - Break up sentence pattern regularity with varied sentence lengths and thought patterns
          - Reconstruct parts of the discussion from a personal perspective (e.g., "I believe," "from this angle")

        Based on the text's AI probability of {ai_probability}%, please apply the following optimization strategy:
        """
        
        # æ ¹æ®ä¸åŒAIç‡èŒƒå›´æ·»åŠ å…·ä½“ä¼˜åŒ–ç­–ç•¥
        if ai_probability > 70:
            system_prompt += """
            [DEEP OPTIMIZATION] Required changes:
              * Prioritize paragraph restructuring, breaking longer paragraphs into multiple shorter ones
              * Actively add academic citations, finding appropriate reference support for high-risk content
              * Thoroughly break sentence structure regularity, introducing natural variations in sentence length
              * Add conversational but academically acceptable phrases ("actually," "to be honest," "it's worth noting")
              * Moderately introduce transitions ("however," "nevertheless," "but looking back") and small-scale jump thinking
              * Reconstruct parts of the argument from a personal perspective ("I believe," "from this angle")
              * Replace overly textbook explanations with less "perfect" but still accurate explanations
              * Consider streamlining or physically removing non-core content
            """
        elif 60 <= ai_probability <= 70:
            system_prompt += """
            [MODERATE ADJUSTMENT] Required changes:
              * Apply paragraph restructuring to divide higher-risk paragraphs appropriately
              * Add 1-2 appropriate academic citations at key points
              * Preserve some original structure, but target overly regular paragraphs for adjustment
              * Add a small amount of personal insight and conversational connectors without affecting academic rigor
              * While maintaining the main arguments, slightly adjust the path of reasoning to make it more natural
              * Use synonym replacement to substitute obvious AI characteristic vocabulary with more humanized expressions
            """
        elif 50 <= ai_probability < 60:
            system_prompt += """
            [LIGHT OPTIMIZATION] Required changes:
              * Apply paragraph restructuring to individual sentences with obvious AI characteristics
              * Mainly preserve the original text, only fine-tuning the most obvious AI features
              * Replace 1-2 overly standardized expressions with more humanized tones
              * Adjust the structure of individual sentences while maintaining the overall appearance
              * Add appropriate conversational expressions like "actually," "it's worth noting," etc.
            """
        else:
            system_prompt += """
            [MAINTAIN ORIGINAL] AI probability below 50%:
              * The text already has good human writing characteristics
              * No need for extensive modifications; can maintain the original form
              * If needed, only adjust individual obviously mechanical expressions
              * Consider adding 1-2 personal opinion expressions
            """
        
        # æ·»åŠ é€šç”¨è¦æ±‚
        system_prompt += """
        All optimizations should:
        - Maintain basic academic writing standards, professionalism, and rigor
        - Ensure terminology accuracy remains unchanged
        - Maintain professional rigor while introducing conversational elements
        - Avoid excessive adjustments that distort content
        - Add appropriate personal perspective statements without compromising existing professionalism

        Please directly output the optimized text without explaining your modifications.
        """
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ]
        }
        
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code == 200:
            response_data = response.json()
            optimized_text = response_data["choices"][0]["message"]["content"]
            return optimized_text
        else:
            st.error(f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
            return text
            
    except Exception as e:
        st.error(f"è°ƒç”¨DeepSeek APIæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return text  # å‡ºé”™æ—¶è¿”å›åŸæ–‡æœ¬

# å¤„ç†Wordæ–‡æ¡£ä¸Šä¼ 
def process_docx_upload(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„Wordæ–‡æ¡£ï¼Œå¹¶ä¿ç•™åŸæœ‰æ ¼å¼"""
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„æ–‡æ¡£
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        
        # è¯»å–æ–‡æ¡£
        doc = Document(tmp_path)
        os.unlink(tmp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        
        # æå–æ®µè½åŠå…¶æ ¼å¼
        paragraphs = []
        styles = []  # å­˜å‚¨æ¯ä¸ªæ®µè½çš„æ ·å¼ä¿¡æ¯

        for para in doc.paragraphs:
            if para.text.strip():  # åªå¤„ç†éç©ºæ®µè½
                paragraphs.append(para.text)
                
                # ä¿å­˜æ®µè½æ ·å¼ä¿¡æ¯
                para_style = {
                    'style_name': para.style.name,
                    'alignment': para.alignment,
                    'runs': []
                }
                
                # ä¿å­˜æ¯ä¸ªrunçš„æ ¼å¼ä¿¡æ¯
                for run in para.runs:
                    # å¤„ç†å­—ä½“é¢œè‰²
                    has_color = False
                    color_rgb = None
                    
                    # å®‰å…¨åœ°è·å–é¢œè‰²ä¿¡æ¯
                    if hasattr(run, 'font') and hasattr(run.font, 'color'):
                        try:
                            font_color = run.font.color
                            if font_color and hasattr(font_color, 'rgb') and font_color.rgb:
                                has_color = True
                                # è·å–é¢œè‰²å€¼ï¼Œå¯èƒ½æ˜¯æ•´æ•°æˆ–å…¶ä»–ç±»å‹
                                color_rgb = font_color.rgb
                        except:
                            pass
                    
                    run_style = {
                        'text': run.text,
                        'bold': run.bold,
                        'italic': run.italic,
                        'underline': run.underline,
                        'font_size': run.font.size if run.font.size else None,
                        'font_name': run.font.name if run.font.name else None,
                        'has_color': has_color,
                        'color_rgb': color_rgb
                    }
                    para_style['runs'].append(run_style)
                
                styles.append(para_style)
        
        st.session_state.doc = doc
        st.session_state.paragraphs = paragraphs
        st.session_state.modified_paragraphs = paragraphs.copy()
        st.session_state.paragraph_styles = styles
        st.session_state.ai_probabilities = [50] * len(paragraphs)  # é»˜è®¤æ¦‚ç‡å€¼
        
        return True
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

# è·å–æ–‡æœ¬çš„é¢œè‰²æ ‡è®°
def get_color_class(ai_probability):
    """æ ¹æ®AIç”Ÿæˆæ¦‚ç‡è¿”å›ç›¸åº”çš„é¢œè‰²ç±»å"""
    if ai_probability > 70:
        return "color-red"
    elif 60 <= ai_probability <= 70:
        return "color-orange"
    elif 50 <= ai_probability < 60:
        return "color-purple"
    else:
        return "color-black"

# è·å–æ®µè½åŸå§‹æ ¼å¼çš„HTMLæ ·å¼
def get_paragraph_style_html(para_idx):
    """æ ¹æ®ä¿å­˜çš„æ®µè½æ ·å¼ä¿¡æ¯ç”ŸæˆHTMLæ ·å¼"""
    if not hasattr(st.session_state, 'paragraph_styles') or para_idx >= len(st.session_state.paragraph_styles):
        return ""
    
    style = st.session_state.paragraph_styles[para_idx]
    style_str = ""
    
    # æ·»åŠ å¯¹é½æ–¹å¼
    if style['alignment'] == 1:  # å±…ä¸­
        style_str += "text-align: center; "
    elif style['alignment'] == 2:  # å³å¯¹é½
        style_str += "text-align: right; "
    elif style['alignment'] == 3:  # ä¸¤ç«¯å¯¹é½
        style_str += "text-align: justify; "
    
    # å¦‚æœæ®µè½æœ‰runsï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªrunçš„æ ¼å¼ä½œä¸ºé»˜è®¤æ ¼å¼
    if style['runs'] and len(style['runs']) > 0:
        first_run = style['runs'][0]
        
        if first_run['bold']:
            style_str += "font-weight: bold; "
        if first_run['italic']:
            style_str += "font-style: italic; "
        if first_run['underline']:
            style_str += "text-decoration: underline; "
        if first_run['font_size'] is not None:
            # å°†ç£…è½¬æ¢ä¸ºåƒç´ ï¼ˆå¤§è‡´è½¬æ¢ï¼‰
            pt_size = first_run['font_size'] / 12700  # å°†EMUè½¬æ¢ä¸ºç£…
            px_size = pt_size * 1.33  # ç£…è½¬åƒç´ çš„å¤§è‡´è½¬æ¢
            style_str += f"font-size: {px_size}px; "
        if first_run['font_name'] is not None:
            style_str += f"font-family: '{first_run['font_name']}', sans-serif; "
        
        # ä½¿ç”¨åŸå§‹æ–‡æœ¬é¢œè‰²ï¼Œå¦‚æœæœ‰
        if first_run['has_color'] and first_run['color_rgb']:
            try:
                # ç®€åŒ–é¢œè‰²å¤„ç†é€»è¾‘
                rgb = first_run['color_rgb']
                if isinstance(rgb, int):
                    # å¦‚æœæ˜¯æ•´æ•°å€¼ï¼Œç›´æ¥å¤„ç†
                    r = rgb & 0xFF
                    g = (rgb >> 8) & 0xFF
                    b = (rgb >> 16) & 0xFF
                    style_str += f"color: rgb({r}, {g}, {b}); "
                elif hasattr(rgb, '_rgb'):
                    # å¤„ç†æŸäº›é¢œè‰²å¯¹è±¡
                    color_value = rgb._rgb
                    if color_value is not None:
                        style_str += f"color: #{color_value:06x}; "
                else:
                    # é»˜è®¤ä½¿ç”¨é»‘è‰²
                    style_str += "color: black; "
            except Exception as e:
                # å¦‚æœè§£æé¢œè‰²å‡ºé”™ï¼Œä½¿ç”¨é»˜è®¤é»‘è‰²
                style_str += "color: black; "
    
    return style_str

# å¯¼å‡ºä¿®æ”¹åçš„æ–‡æ¡£
def export_modified_doc():
    """å¯¼å‡ºä¿®æ”¹åçš„Wordæ–‡æ¡£ï¼Œä¿ç•™åŸæ ¼å¼"""
    try:
        if st.session_state.doc is None:
            st.error("æ²¡æœ‰å¯å¯¼å‡ºçš„æ–‡æ¡£")
            return None
        
        # åˆ›å»ºæ–°æ–‡æ¡£
        doc = Document()
        
        # è·å–ä¿®æ”¹åçš„æ–‡æœ¬æ®µè½
        modified_paragraphs = st.session_state.modified_paragraphs
        
        # å¤åˆ¶åŸæ–‡æ¡£çš„æ®µè½å’Œæ ¼å¼
        for para_idx, para in enumerate(st.session_state.doc.paragraphs):
            if para.text.strip() and para_idx < len(modified_paragraphs):  # åªå¤„ç†éç©ºæ®µè½
                # åˆ›å»ºæ–°æ®µè½å¹¶è®¾ç½®æ–‡æœ¬
                new_para = doc.add_paragraph()
                
                # åº”ç”¨åŸæ®µè½çš„æ ·å¼
                new_para.style = para.style
                
                # åˆ¤æ–­æ˜¯å¦æœ‰ä¿å­˜çš„æ ·å¼ä¿¡æ¯
                if hasattr(st.session_state, 'paragraph_styles') and para_idx < len(st.session_state.paragraph_styles):
                    # æ·»åŠ ä¿®æ”¹åçš„æ–‡æœ¬å†…å®¹ï¼ˆä¸å¤„ç†å¤æ‚æ ¼å¼ï¼Œåªæ·»åŠ çº¯æ–‡æœ¬ï¼‰
                    new_para.add_run(modified_paragraphs[para_idx])
                else:
                    # æ²¡æœ‰ä¿å­˜çš„æ ·å¼ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ æ–‡æœ¬
                    new_para.add_run(modified_paragraphs[para_idx])
        
        # åˆ›å»ºå†…å­˜ä¸­çš„å­—èŠ‚æµ
        doc_bytes = io.BytesIO()
        doc.save(doc_bytes)
        doc_bytes.seek(0)
        
        return doc_bytes
    except Exception as e:
        st.error(f"å¯¼å‡ºæ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None

# åˆ›å»ºä¸‹è½½é“¾æ¥
def get_download_link(doc_bytes, filename="modified_document.docx"):
    """ç”Ÿæˆæ–‡æ¡£ä¸‹è½½é“¾æ¥"""
    b64 = base64.b64encode(doc_bytes.read()).decode()
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{filename}">ç‚¹å‡»ä¸‹è½½ä¿®æ”¹åçš„æ–‡æ¡£</a>'
    return href

# é¡µè„š
st.markdown("---")
st.markdown("#### ğŸ¯ **AIGCæ–‡æœ¬é™é‡ä¿®æ”¹å·¥å…·** - è®©AIç”Ÿæˆæ–‡æœ¬æ›´æ¥è¿‘äººç±»å†™ä½œï¼Œè½»æ¾é€šè¿‡æ£€æµ‹å·¥å…·ï¼")
st.markdown("""
- ğŸ”´ **çº¢è‰² (>70% AIæ¦‚ç‡)**: éœ€è¦æ·±åº¦æ”¹å†™
- ğŸŸ  **æ©™è‰² (60%-70%)**: é€‚åº¦ä¼˜åŒ–
- ğŸŸ£ **ç´«è‰² (50%-60%)**: è½»å¾®è°ƒæ•´
- âš« **é»‘è‰² (<50%)**: ä¿ç•™åŸæ–‡
""") 

st.markdown("""
#### é™é‡æ ¸å¿ƒç­–ç•¥:
- ğŸ“ **ç‰©ç†åˆ é™¤æ³•**: è¯†åˆ«å¹¶åˆ é™¤é«˜é£é™©éæ ¸å¿ƒå†…å®¹
- ğŸ“š **å¼•ç”¨å¤§æ³•**: æ·»åŠ å­¦æœ¯å¼•ç”¨ï¼Œé™ä½AIæ£€æµ‹é£é™©
- ğŸ“‹ **åˆ†æ®µæ³•**: å°†é•¿æ®µè½åˆ†å‰²ï¼Œé¿å…"è¿å"æ•ˆåº”
- ğŸ”„ **åŒä¹‰è¯æ›¿æ¢**: ç”¨å£è¯­åŒ–è¡¨è¾¾æ›¿ä»£æœºå™¨åŒ–è¯­è¨€
""") 
